import re
import time
import requests
from bs4 import BeautifulSoup
from mysql.connector import connect, Error


def time_decorator(func):
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        end = time.perf_counter()
        total = end - start
        print(f'FUNC {func.__name__} TIME IS {total}')
        return result
    return wrapper


def db_decorator(func):
    def wrapper(*args, **kwargs):
        con = connect(
            host='localhost',
            user='root',
            password=''
        )
        try:
            result = func(*args, connection=con, *kwargs)
        except Error as e:
            print(e)
            print('SQL failed!')
        else:
            con.commit()
            return result
        finally:
            con.close()

    return wrapper


class ParseAccount:
    def __init__(self, page, account_id, name_class='profile-user-info_name', name_tag='h1', menu_class='mctc_navMenu',
                 menu_tag='nav', data_class='mctc_navMenuSec', a1_tag='a', a2_tag='a'):
        self.page = page
        self.account_id = account_id
        self.a1_tag = a1_tag
        self.a2_tag = a2_tag
        self.name_class = name_class
        self.name_tag = name_tag
        self.menu_class = menu_class
        self.menu_tag = menu_tag
        self.data_class = data_class
        self.data_collection = []

    def push_to_data_collection(self):
        request = requests.get(self.page)
        if request.status_code == 200:
            soup = BeautifulSoup(request.text, 'html.parser')

            name = soup.find(self.a1_tag, class_=self.name_class).find(self.name_tag)
            data = soup.find(self.menu_tag, class_=self.menu_class).find_all(self.a2_tag, self.data_class)

            rough_data = [(re.split('(\d+)', ''.join(d.text.split('\xa0')))) for d in data]
            normalized_data = self.normalize_data(rough_data)

            self.data_collection.append((name.text, self.account_id, *normalized_data))
        else:
            return

    @staticmethod
    def normalize_data(collection):
        normalized_collection = []

        for element in collection[1:]:
            if len(element) == 1:
                normalized_collection.append(element + ['0'])
            else:
                normalized_collection.append(element)

        return [element[1] for element in normalized_collection]


class DataBase:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super().__new__(cls)

        return cls._instance

    def __init__(self, db_name):
        self._db_name = db_name

    @db_decorator
    def create_db(self, *args, **kwargs):
        connection = kwargs.pop('connection')
        cursor = connection.cursor()

        cursor.execute(f"CREATE DATABASE {self._db_name}")
        print('DATABASE SUCCESSFULLY CREATED')

    @db_decorator
    def create_table(self, *args, **kwargs):
        connection = kwargs.pop('connection')
        cursor = connection.cursor()

        cursor.execute(f'USE {self._db_name}')
        cursor.execute(f"CREATE TABLE {args[0]} ({', '.join([arg for arg in args[1:]])});")
        print(f'TABLE {args[0]} SUCCESSFULLY CREATED')

    @db_decorator
    def send_to_table(self, table_name: str, columns: tuple, collection: list, *args, **kwargs) -> None:
        connection = kwargs.pop('connection')
        cursor = connection.cursor()

        insert = '%s,' * len(columns)
        cursor.execute(f"USE {self._db_name}")
        if len(collection) > 1:
            cursor.executemany(f"REPLACE INTO {table_name} ({', '.join([col for col in columns])}) VALUES ({insert[:-1]})", collection)
        else:
            cursor.execute(f"REPLACE INTO {table_name} ({', '.join([col for col in columns])}) VALUES ({insert[:-1]})", collection)

        print("DATA SUCCESSFULLY ADDED TO DATABASE")

    @db_decorator
    def get_data_for_parse(self, table_name, *args, **kwargs):
        connection = kwargs.pop('connection')
        cursor = connection.cursor()

        cursor.execute(f"USE {self._db_name}")
        cursor.execute(f"SELECT * FROM {table_name}")

        return [item for item in cursor.fetchall()]

    @db_decorator
    def drop_table(self, table_name: str, *args, **kwargs) -> None:
        connection = kwargs.pop('connection')
        cursor = connection.cursor()

        cursor.execute(f"USE {self._db_name}")
        cursor.execute(f"DROP TABLE {table_name}")
        print("TABLE SUCCESSFULLY DROPPED")

    @db_decorator
    def update_table(self, table_name: str, columns: tuple, collection: list, *args, **kwargs) -> None:
        connection = kwargs.pop('connection')
        cursor = connection.cursor()

        columns = tuple([col + "=%s" for col in columns])
        cursor.execute(f"USE {self._db_name}")
        if len(collection) > 1:
            cursor.executemany(f"UPDATE {table_name} SET {', '.join([col for col in columns])} WHERE account_id=%s;",
                               collection)
        else:
            cursor.execute(f"UPDATE {table_name} SET {', '.join([col for col in columns])} WHERE account_id=%s;",
                           collection)
        print("DATA SUCCESSFULLY UPDATED")


@time_decorator
def main(ACCOUNTS_FOR_SCRAPPING):
    database = DataBase('ok')

    # Creating DB
    try:
        database.create_db()
    except Exception:
        print('Database already exists')

    # Creating tables
    try:
        database.create_table('accounts', 'account_id int NOT NULL AUTO_INCREMENT', 'link VARCHAR(100) NOT NULL',
                              'PRIMARY KEY (account_id)', 'UNIQUE KEY unique_link (link)')
    except Exception:
        print('Table already exists')
    try:
        database.create_table('data', 'data_id int NOT NULL AUTO_INCREMENT', 'account_id int NOT NULL',
                              'name VARCHAR(255)', 'followers int', 'photo int', 'notes int', 'account_groups int',
                              'games int', 'video int', 'PRIMARY KEY (data_id)',
                              'FOREIGN KEY (account_id) REFERENCES accounts(account_id) ON DELETE CASCADE',
                              'UNIQUE KEY (account_id)')
    except Exception:
        print('Table already exists')
    try:
        database.create_table('data_groups', 'group_id int NOT NULL AUTO_INCREMENT', 'account_id int NOT NULL',
                              'group_name VARCHAR(255)', 'followers int', 'goods int', 'themes int', 'photo int',
                              'video int', 'PRIMARY KEY (group_id)',
                              'FOREIGN KEY (account_id) REFERENCES accounts(account_id) ON DELETE CASCADE',
                              'UNIQUE KEY (account_id)')
    except Exception:
        print('Table already exists')

    # Fill table accounts with initial data
    # also prevents duplicates if data already exists in DB
    database.send_to_table('accounts', ('link',), ACCOUNTS_FOR_SCRAPPING)

    def generate_send_data():
        # Drag info from accounts for scrapping
        data_for_scrapping = database.get_data_for_parse('accounts')

        # Collection for initial sending data to DB
        accounts_collection, groups_collection = [], []

        def add_if_not_empty(collection, page_obj):
            if len(page_obj.data_collection[-1]) > 1:
                collection.append(*page_obj.data_collection)

        # If there is a navigation element "GOODS" then we add 0 to object to its index 2
        def normalize_different_pages(page_obj, groups_collection):
            normalized_data = list(*page_obj.data_collection)
            normalized_data.insert(2, 0)
            page_obj.data_collection = (normalized_data,)
            add_if_not_empty(groups_collection, page_obj)

        # Parse pages for initial DB migration
        for id, page in data_for_scrapping:
            try:
                page_obj = ParseAccount(page, id)
                page_obj.push_to_data_collection()
                add_if_not_empty(accounts_collection, page_obj)

            except:
                try:
                    page_obj = ParseAccount(page, id, 'group-name_t', 'h1', 'mctc_navMenu __groups', 'nav', 'mctc_navMenuSec', 'div', 'span')
                    page_obj.push_to_data_collection()
                    if len(page_obj.data_collection[-1]) == 6:
                        normalize_different_pages(page_obj, groups_collection)

                    # If there is another cluster which is used to navigate on page
                    if len(page_obj.data_collection[-1]) <= 3:
                        page_obj = ParseAccount(page, id, 'group-name_t', 'h1', 'mctc_navMenu __groups', 'nav', 'mctc_navMenuSec', 'div', 'a')
                        page_obj.push_to_data_collection()
                        if len(page_obj.data_collection[-1]) != 7:
                            # If there is no navigation element "GOODS" then we add 0 to object
                            normalize_different_pages(page_obj, groups_collection)
                        else:
                            add_if_not_empty(groups_collection, page_obj)

                    groups_collection.append(*page_obj.data_collection)
                except Exception:
                    print('Problem with page occured!')

        return accounts_collection, groups_collection

    # Generate collections of accounts and groups
    collection_of_accounts, collection_of_groups = generate_send_data()

    # Initial migration
    database.send_to_table('data', ('name', 'account_id', 'followers', 'photo', 'notes', 'account_groups', 'games', 'video',), collection_of_accounts)
    database.send_to_table('data_groups', ('group_name', 'account_id', 'goods', 'themes', 'photo', 'video', 'followers',), collection_of_groups)

    # If we need infinite parse for our database
    """
    # Updating existing data \ infinite parse
    while True:
        # Optimize both collections for updating
        accounts_optimized_collection = [tuple(list(col)+[col[1]]) for col in collection_of_account]
        groups_optimized_collection = [tuple(list(col)+[col[1]]) for col in collection_of_groups]

        # Migration (update)
        database.update_table('data', ('name', 'account_id', 'followers', 'photo', 'notes', 'account_groups', 'games', 'video',), accounts_optimized_collection)
        database.update_table('data_groups', ('group_name', 'account_id', 'goods', 'themes', 'photo', 'video', 'followers',), groups_optimized_collection)
    """


if __name__ == '__main__':
    with open('accounts_for_scarpping.txt', 'r') as accs:
        accounts_for_scarpping = tuple([(line.strip(),) for line in accs.readlines()])
        main(accounts_for_scarpping)
